# ğŸŒ GraphVectorize: Multi-Agent Vector Database System

## ğŸ“ Overview

GraphVectorize is an innovative project demonstrating the power of LangGraph for creating a sophisticated, multi-agent vector database system. This solution leverages advanced AI agents to manage, process, and retrieve vector embeddings with intelligent coordination.

## ğŸŒŸ Key Features

- ğŸ¤– **Multi-Agent Architecture**: Intelligent agents for different vector database operations
- ğŸ” **Semantic Search**: Advanced contextual retrieval and similarity matching
- ğŸ§  **Adaptive Reasoning**: Agents collaborate to optimize vector storage and querying
- ğŸ˜ **PostgreSQL Integration**: Robust vector storage using `pgvector`
- ğŸ³ **Dockerized Environment**: Simplified deployment and setup
- ğŸ“Š **Flexible Metadata Handling**: Intelligent metadata management and filtering
- ğŸ”­ **Comprehensive Monitoring**: Integrated Prometheus and Grafana dashboards

## ğŸ—ï¸ Project Structure

```
ğŸ“ graphvectorize/
â”‚
â”œâ”€â”€ ğŸ³ Dockerfile              # Container configuration
â”œâ”€â”€ ğŸ“ docker-compose.yml       # Multi-container Docker setup
â”œâ”€â”€ ğŸ“‹ pyproject.toml           # Poetry dependency management
â”œâ”€â”€ ğŸ“Š prometheus.yml           # Prometheus monitoring configuration
â”œâ”€â”€ ğŸ main.py                  # Core application logic
â”œâ”€â”€ ğŸ¤– agents/                  # Agent implementation directory
â”‚   â”œâ”€â”€ retrieval_agent.py      # Document retrieval specialist
â”‚   â”œâ”€â”€ embedding_agent.py      # Embedding generation agent
â”‚   â””â”€â”€ metadata_agent.py       # Metadata management agent
â”œâ”€â”€ ğŸ—„ï¸ db_setup.py              # Database initialization script
â””â”€â”€ ğŸ“– README.md                # Project documentation
```

## ğŸ› ï¸ Prerequisites

- ğŸ’» Docker and Docker Compose
- ğŸ Python 3.11+
- ğŸ”‘ OpenAI API Key
- ğŸŒ LangGraph
- ğŸ™ GitHub Account (for contributing)

## ğŸš€ Quick Start Guide

### 1. Fork the Repository ğŸ´

1. Visit the repository: https://github.com/YourOrg/graphvectorize
2. Click the **Fork** button in the top-right corner
3. Choose your personal GitHub account

### 2. Clone Your Forked Repository ğŸ“¦

```bash
# Replace {your-username} with your GitHub username
git clone https://github.com/{your-username}/graphvectorize.git
cd graphvectorize

# Add upstream remote
git remote add upstream https://github.com/YourOrg/graphvectorize.git
```

### 3. Set Up Environment Variables ğŸ”§

Create a `.env` file in the project root:

```env
DATABASE_URL=postgresql://graphuser:graphpassword@postgres:5432/vectordb
REDIS_URL=redis://redis:6379/0
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key
```

### 4. Build and Launch ğŸš¢

```bash
# Start all services
docker-compose up --build

# Or run specific services
docker-compose up app postgres redis
```

## ğŸ”¬ Infrastructure Components

### Docker Composition

Our `docker-compose.yml` provides a robust multi-service architecture:

- **Main Application**: Python-based LangGraph service
- **PostgreSQL**: Vector database with `pgvector` extension
- **Redis**: Caching and task queuing
- **Adminer**: Database management interface
- **Prometheus**: System and application monitoring
- **Grafana**: Visualization and dashboarding

### Dependency Management

We use Poetry for sophisticated dependency management:
- `pyproject.toml` defines project dependencies
- Supports development and production environments
- Ensures consistent package versions across setups

### Monitoring Stack

- **Prometheus**: Collects metrics from:
  - Application performance
  - Database statistics
  - Redis cache metrics
- **Grafana**: Creates interactive dashboards for real-time insights

## ğŸ’¡ Usage Examples

(Previous usage examples remain the same)

## ğŸš€ Monitoring and Observability

### Accessing Dashboards

- **Prometheus**: `http://localhost:9090`
- **Grafana**: `http://localhost:3000`
- **Adminer**: `http://localhost:8080`

### Metrics Tracking

Configure custom metrics in your agents:

```python
from prometheus_client import Counter, Gauge

# Example agent metrics
EMBEDDING_REQUESTS = Counter(
    'agent_embedding_requests_total', 
    'Total embedding generation requests'
)
VECTOR_SEARCH_LATENCY = Gauge(
    'agent_vector_search_latency_seconds', 
    'Latency of semantic search operations'
)
```

## ğŸ¤ Contributing Workflow

(Previous contribution guidelines remain the same)

## ğŸ›¡ï¸ Troubleshooting

- **Docker Composition**
  - Verify all service dependencies
  - Check container logs with `docker-compose logs <service>`

- **Performance Monitoring**
  - Review Prometheus metrics
  - Analyze Grafana dashboards
  - Adjust resource allocations in `docker-compose.yml`

## ğŸš€ Future Roadmap

- [ ] Multi-model support
- [ ] Advanced agent reasoning capabilities
- [ ] Distributed agent architectures
- [ ] Enhanced observability and tracing
- [ ] Custom Grafana dashboards

## ğŸ“œ License

MIT License - See `LICENSE` file for details.

## ğŸ’Œ Disclaimer

This project demonstrates multi-agent vector database interactions. Adapt carefully for production use and comply with AI service providers' terms.

## ğŸŒ Connect

- **Project Link**: [GitHub Repository](https://github.com/decagondev/graph-vectorize-starter)
- **Issues**: [Project Issues](https://github.com/decagondev/graph-vectorize-starter/issues)

---

**Empower Your AI Workflows!** ğŸš€ğŸ¤–
